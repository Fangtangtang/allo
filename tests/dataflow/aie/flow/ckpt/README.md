# Experimental Implementation
## CT forwarding

Shim -> Mem -> Comp -> adjacent Comp

```python
def test_transfer():
    Ty = int32
    M = 16

    @df.region()
    def top():
        pipe: Stream[Ty[M], 2]

        @df.kernel(mapping=[1])
        def producer(A: Ty[M]):
            # send data
            pipe.put(A)

        @df.kernel(mapping=[1])
        def consumer(B: Ty[M]):
            # receive data
            B[:] = allo.add(pipe.get(), 1)

    A = np.random.randint(0, 64, (M)).astype(np.int32)
    B = np.zeros((M), dtype=np.int32)

    mod = df.build(top, target="aie")
    mod(A, B)
    np.testing.assert_allclose(A + 1, B, atol=1e-5)
    print("Passed!")
```

- [objectfifo.mlir](./transfer/objectfifo.mlir): generated by allo
- [flow.mlir](./transfer/flow.mlir): partially lowered + manually clean up
- [opt_flow.mlir](./transfer/opt_flow.mlir): manually simplified, remove redundent `memref.copy`

## CT reuse
```python
def test_reuse():
    Ty = int32
    M = 16

    @df.region()
    def top():
        pipe: Stream[Ty[M], 2]

        @df.kernel(mapping=[1])
        def producer(A: Ty[M], B0: Ty[M]):
            B0[:] = allo.add(A, 1)
            # send data
            pipe.put(A)

        @df.kernel(mapping=[1])
        def consumer(B1: Ty[M]):
            # receive data
            B1[:] = allo.add(pipe.get(), 1)

    A = np.random.randint(0, 64, (M)).astype(np.int32)
    B0 = np.zeros((M), dtype=np.int32)
    B1 = np.zeros((M), dtype=np.int32)

    mod = df.build(top, target="aie")
    mod(A, B0, B1)
    np.testing.assert_allclose(A + 1, B0, atol=1e-5)
    np.testing.assert_allclose(A + 1, B1, atol=1e-5)
    print("Passed!")
```

- [objectfifo.mlir](./reuse/objectfifo.mlir): generated by allo
- [flow.mlir](./reuse/flow.mlir): partially lowered + manually clean up
- [opt_flow.mlir](./reuse/opt_flow.mlir): manually simplified, remove redundent `memref.copy`

**careful with `lock`!**

## Dummy matmul (CT reuse)
```python
def test_cooperate_gemm():
    Ty = bfloat16
    M = K = N = 32
    P = 4

    Ly = Layout("RS0")

    @df.region()
    def top():
        pipe_A: Stream[Ty[M, K], 2][P]
        pipe_B: Stream[Ty[K, N], 2][P]

        @df.kernel(mapping=[P])
        def producer(A: Ty[M, K], B: Ty[K, N], C: Ty[M, N * P] @ Ly):
            C[:, :] = allo.matmul(A, B)
            # send data
            p = df.get_pid()
            pipe_A[p].put(A)
            pipe_B[p].put(B)

        @df.kernel(mapping=[P])
        def consumer(C_: Ty[M, N * P] @ Ly):
            p = df.get_pid()
            # receive data
            C_[:, :] = allo.matmul(pipe_A[p].get(), pipe_B[p].get())

    A = (np.random.random((M, K)) * 0.1).astype(np_bfloat16)
    B = (np.random.random((K, N)) * 0.1).astype(np_bfloat16)
    C = np.zeros((M, N * P)).astype(np_bfloat16)
    C_ = np.zeros((M, N * P)).astype(np_bfloat16)

    groups = []
    for i in range(P):
        groups.append((f"producer_{i}", f"consumer_{i}"))
    # mod = df.build(top, target="aie", mapping_primitives=[("bundle", groups)])
    # mod(A, B, C, C_)

    allo.backend.aie._call_prj("top.prj", [Ty, Ty, Ty, Ty], 65536, [0, 1], [2, 3], A, B, C, C_)
    
    print("[Warning]: dataflow test only, output won't be correct!")

```

[NOTE]: vectorized version not supported currently, so I disable vectorization and manually modify the generated `top.mlir`

- [objectfifo.mlir](./dummy_matmul/objectfifo.mlir): generated by allo
- [flow.mlir](./dummy_matmul/flow.mlir): partially lowered + manually clean up
- [opt_flow.mlir](./dummy_matmul/opt_flow.mlir): manually simplified, remove redundent `memref.copy`

